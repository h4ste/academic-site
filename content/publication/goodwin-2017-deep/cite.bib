@inproceedings{goodwin2017deep,
 abstract = {Secondary use of electronic health records (EHRs) often relies on the ability to automatically identify and extract information from EHRs. Unfortunately, EHRs are known to suffer from a variety of idiosyncrasies – most prevalently, they have been shown to often omit or underspecify information. Adapting traditional machine learning methods for inferring underspecified information relies on manually specifying features characterizing the specific information to recover (e.g. particular findings, test results, or physician’s impressions). By contrast, in this paper, we present a method for jointly (1) automatically extracting word- and report-level features and (2) inferring underspecified information from EHRs. Our approach accomplishes these two tasks jointly by combining recent advances in deep neural learning with access to textual data in electroencephalogram (EEG) reports. We evaluate the performance of our model on the problem of inferring the neurologist’s over-all impression (normal or abnormal) from electroencephalogram (EEG) reports and report an accuracy of 91.4% precision of 94.4% recall of 91.2% and F1 measure of 92.8% (a 40% improvement over the performance obtained using Doc2Vec). These promising results demonstrate the power of our approach, while error analysis reveals remaining obstacles as well as areas for future improvement.},
 author = {Goodwin, Travis R and Harabagiu, Sanda M},
 booktitle = {Proceedings of the 2017 American Medical Informatics Association (AMIA) Summit on Clinical Research Informatics},
 month = {March},
 pages = {112--121},
 publisher = {American Medical Informatics Association},
 title = {Deep Learning from EEG Reports for Inferring Underspecified Information},
 url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543361/},
 year = {2017}
}

